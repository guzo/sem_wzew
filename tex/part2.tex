%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Konkretne przykłady} %FIXME: mniej głupia nazwa
\begin{frame}[fragile, allowframebreaks]{Przykładowe optymalizacje}
	\begin{block}{Wybór algorytmu/architektury}
		\begin{itemize}
			\item Złożoność obliczeniowa
				\begin{itemize}
					\item indeksowanie w bazach danych (nlgn+klgn vs. kn)
					\item QS/SS, fallback
					\item QS/HS
					\item custom heap w QS
					\item buforowanie (przykład)
					\item fajne-na-papierze-niepraktyczne-w-realu mnozenia macierzy: \url{http://en.wikipedia.org/wiki/File:Bound_on_matrix_multiplication_omega_over_time.svg}
				\end{itemize}
			\item Lazy evaluation
			\item Memory access patterns
				\begin{itemize}
					\item AoS vs. SoA, row/column major
					\item cache aware (liniowo, reuse, jawny prefetch)
					\item cache oblivious
				\end{itemize}
		\end{itemize}
	\end{block}
	\begin{block}{Na poziomie kodu źródłowego}
		\begin{itemize}
			\item inlining
				\begin{itemize}
					\item enabling transform dla m.in. zwijania/optymalizacji wykorzystania rejestrów
					\item przy małych funkcjach (gettery!) - więcej kodu na wywołanie i sprzątanie niż na ciało
					\item funkcje użyte tylko raz (bo przejrzystość) (static)
				\end{itemize}
			\item loop unrolling
				\begin{itemize}
					\item trochę pokrewne z inline
					\item I\$
					\item dawniej: Duff's device
					\item \#pragma - intel
					\item \verb*%BOOST_PP%
				\end{itemize}
			\item tail recursion elimination
			\item dead code elimination
			\item jump threading
		\end{itemize}
	\end{block}
	\begin{block}{Na poziomie IR}
		\begin{itemize}
			\item dead code elimination
				\begin{itemize}
					\item available expression analysis
					\item live variable analysis
					\item global value numbering
				\end{itemize}
			\item peephole/window optimization (kategoria)
				\begin{itemize}
					\item strength reduction
					\item constant folding
				\end{itemize}
		\end{itemize}
	\end{block}
	\begin{block}{Na poziomie asm/przejście z IR}
		\begin{itemize}
			\item instruction selection - jedna z metod strength reduction
				\begin{itemize}
					\item lea zamiast prostych mnozen (bez side effcts, ustalone argumenty)
					\item shifty zamiast mnozen/dzieleń przez 2**n, \texttt{xor reg, reg} vs. \texttt{mov reg, 0}: \url{http://www.nynaeve.net/?p=64}
					\item "Division by Invariant Integers using Multiplication"
				\end{itemize}
			\item instruction scheduling
			\item calling conventions
			\item stack reuse
		\end{itemize}
	\end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Wektoryzacja}
	\begin{block}{Compiler intrinsics: GCC}
		\begin{cpp}
			typedef float v4f __attribute__ (( vector_size(4*4) ));
			v4f a = {3,2,32,8};
			v4f b = {1,2,32,8};
			v4i s = {3,2,1,0};
			v4i e = (a == b); // -1 :== all bits set
			a = __builtin_shuffle(a+b, s);
			a = __builtin_ia32_rsqrtps(a);
		\end{cpp}
		\url{http://software.intel.com/en-us/articles/intel-intrinsics-guide}
	\end{block}
	\begin{block}{Nagłówki INTELa: przenośne między kompilatorami, ale nie architekturami}
		Popularne kompilatory mają swoje wersje, opakowujące swoje rozszerzenia
		\begin{verbatim}
		//MMX    :  <mmintrin.h>
		//SSE    : <xmmintrin.h>
		//SSE2   : <emmintrin.h>
		//SSE3   : <pmmintrin.h>
		//SSSE3  : <tmmintrin.h>
		//SSE4.1 : <smmintrin.h>
		//AES    : <wmmintrin.h>
		//AVX    : <avxintrin.h>
		#include <x86intrin.h> //META
		#if
		\end{verbatim}
	\end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Przykład: clang 3.3}
	\begin{cpp}
	int sum_elements(int *A, int n) {
		int sum = 0;
		for(int i = 0; i < n; ++i)
			sum += A[i];
		return sum;
	}
	\end{cpp}
	\begin{verbatim}
	% ...
	LBB0_4:
		movdqu    16(%rdi,%rax,4), %xmm2
		paddd     %xmm2, %xmm1
		movdqu    (%rdi,%rax,4), %xmm2
		paddd     %xmm2, %xmm0
		addq      $8, %rax
		cmpq      %rax, %rcx
	jne       LBB0_4
	% ...
	\end{verbatim}
	\tiny\url{http://blog.llvm.org/2013/05/llvm-33-vectorization-improvements.html}
	vec, instruction scheduling
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%FIXME: wykresy z dema
%FIXME: cache associativity, cache lines, soa aos
%FIXME: matmul (cachegrind, plots), transpose, duff, plots
\begin{frame}[fragile, allowframebreaks]{Pętle: osobna sprawa}
	Dlaczego osobno?
	\begin{block}{Memory access - istotne, warto pomóc}
		\begin{itemize}
			\item tiling/loop nest optimization: matmul
			\item blocking $=>$ automatic parallelisation/vectorisation - matmul
				\begin{itemize}
					\item dependencies (aliasing)
					\item OpenMP
				\end{itemize}
			\item loop unrolling: matmul
			\item loop interchange: matmul (row/column major)
			\item loop fusion/fission
			\item szczególne przypadki
				\begin{itemize}
					\item splitting
					\item peeling
					\item unswitching
				\end{itemize}
		\end{itemize}
	\end{block}
	\begin{block}{Drobne, czasem warto zostawić}
		\begin{itemize}
			\item factoring out of invariants
			\item loop invariant code motion
			\item induction variable elimination (była mowa)
			\item rematerialization (troche jak xor reg,reg)
			\item bounds checking elimination
		\end{itemize}
	\end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Podsumowanie}
	\begin{itemize}
		\item RTFM
		\item Profiler
		\item Cache
	\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Pokrewne zagadnienia}
	\begin{block}{Tyle się zmieściło, bo więcej nie weszło}
		\begin{itemize}
			\item Static code analysis
			\item Object code optimization
			\item Link-time optimization
			\item Profile guieded optimization
			\item Superoptimization
		\end{itemize}
	\end{block}
\end{frame}